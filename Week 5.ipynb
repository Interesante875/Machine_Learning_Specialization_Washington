{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.read_csv('Week_5/lending-club-data.csv')\n",
    "with open('Week_5/module-8-assignment-2-test-idx.json') as f:\n",
    "    test_idx = json.load(f)\n",
    "with open('Week_5/module-8-assignment-2-train-idx.json') as f:\n",
    "    train_idx = json.load(f)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans = loans.drop('bad_loans', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'safe_loans'\n",
    "features = ['grade',                     # grade of the loan (categorical)\n",
    "            'sub_grade_num',             # sub-grade of the loan as a number from 0 to 1\n",
    "            'short_emp',                 # one year or less of employment\n",
    "            'emp_length_num',            # number of years of employment\n",
    "            'home_ownership',            # home_ownership status: own, mortgage or rent\n",
    "            'dti',                       # debt to income ratio\n",
    "            'purpose',                   # the purpose of the loan\n",
    "            'payment_inc_ratio',         # ratio of the monthly payment to income\n",
    "            'delinq_2yrs',               # number of delinquincies\n",
    "             'delinq_2yrs_zero',          # no delinquincies in last 2 years\n",
    "            'inq_last_6mths',            # number of creditor inquiries in last 6 months\n",
    "            'last_delinq_none',          # has borrower had a delinquincy\n",
    "            'last_major_derog_none',     # has borrower had 90 day or worse rating\n",
    "            'open_acc',                  # number of open credit accounts\n",
    "            'pub_rec',                   # number of derogatory public records\n",
    "            'pub_rec_zero',              # no derogatory public records\n",
    "            'revol_util',                # percent of available credit being used\n",
    "            'total_rec_late_fee',        # total late fees received to day\n",
    "            'int_rate',                  # interest rate of the loan\n",
    "            'total_rec_int',             # interest received to date\n",
    "            'annual_inc',                # annual income of borrower\n",
    "            'funded_amnt',               # amount committed to the loan\n",
    "            'funded_amnt_inv',           # amount committed by investors for the loan\n",
    "            'installment',               # monthly payment owed by the borrower\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = loans[[target] + features]\n",
    "prev = len(loans)\n",
    "loans = loans.dropna(axis=0, how='any')\n",
    "now = len(loans)\n",
    "# Count the number of rows with missing data\n",
    "\n",
    "print ('Dropping %s observations; keeping %s ' % (prev - now, now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dummy_target = [col for col, datatype in zip(loans.columns, loans.dtypes) if datatype == object]\n",
    "dummy_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans = pd.get_dummies(loans, columns=dummy_target)\n",
    "loans.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = loans.iloc[train_idx]\n",
    "validation_data = loans.iloc[validation_idx]\n",
    "train_data_X = train_data.drop(['safe_loans'], axis='columns')\n",
    "validation_data_X = validation_data.drop(['safe_loans'], axis='columns')\n",
    "train_data_Y = train_data['safe_loans']\n",
    "validation_data_Y = validation_data['safe_loans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5 = GradientBoostingClassifier(max_depth = 6, n_estimators = 5)\n",
    "model_5.fit(train_data_X, train_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_safe_loans = validation_data[validation_data[target] == 1]\n",
    "validation_risky_loans = validation_data[validation_data[target] == -1]\n",
    "\n",
    "sample_validation_data_risky = validation_risky_loans[0:2]\n",
    "sample_validation_data_safe = validation_safe_loans[0:2]\n",
    "\n",
    "sample_validation_data = sample_validation_data_safe.append(sample_validation_data_risky)\n",
    "sample_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_sample = model_5.predict(sample_validation_data.drop([target], axis = 'columns'))\n",
    "num_err_samples = np.array(prediction_sample ==  sample_validation_data[target].values).sum()\n",
    "print(f'percentage of accuracy is {num_err_samples/float(len(sample_validation_data))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_5.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_sample = model_5.predict_proba(sample_validation_data.drop([target], axis = 'columns'))\n",
    "print(probability_sample[:,1])\n",
    "positive_prob = np.array(probability_sample[:,1])\n",
    "print(f'The sample with highest probability is {np.argmax(positive_prob)} of {max(positive_prob)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_valid = model_5.score(validation_data_X, validation_data_Y)\n",
    "print(score_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#false positive\n",
    "predictions = model_5.predict(train_data_X)\n",
    "false_positive = np.asarray(((predictions==1) * (train_data_Y==-1)), dtype=int).sum()\n",
    "print (false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the number of negatives made by the model.\n",
    "predictions = model_5.predict(train_data_X)\n",
    "false_negative = np.asarray(((predictions==-1) * (train_data_Y==1)),dtype=int).sum()\n",
    "print (false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate the number of false negatives on the validation_data\n",
    "predictions = model_5.predict(validation_data_X)\n",
    "false_negative = np.asarray(((predictions==-1) * (validation_data_Y==1)),dtype=int).sum()\n",
    "print (false_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What is the number of false positives on the validation_data?\n",
    "predictions = model_5.predict(validation_data_X)\n",
    "false_positive = np.asarray(((predictions==1) * (validation_data_Y==-1)),dtype=int).sum()\n",
    "print (false_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print (\"Cost: \",(10000 * false_negative) + (20000 * false_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data['predictions'] = [x[1] for x in model_5.predict_proba(validation_data_X)]\n",
    "top_5 = validation_data.sort_values(by = \"predictions\", ascending=False)[:5]\n",
    "top_5[['grade_A','grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F', 'grade_G']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_5 = validation_data.sort_values(by = \"predictions\", ascending=True)[:5]\n",
    "low_5[['grade_A','grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F', 'grade_G']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10 = GradientBoostingClassifier(n_estimators=10, max_depth=6, verbose=False).fit(train_data_X, train_data_Y)\n",
    "model_50 = GradientBoostingClassifier(n_estimators=50, max_depth=6, verbose=False).fit(train_data_X, train_data_Y)\n",
    "model_100 = GradientBoostingClassifier(n_estimators=100, max_depth=6, verbose=False).fit(train_data_X, train_data_Y)\n",
    "model_200 = GradientBoostingClassifier(n_estimators=200, max_depth=6, verbose=False).fit(train_data_X, train_data_Y)\n",
    "model_500 = GradientBoostingClassifier(n_estimators=500, max_depth=6, verbose=False).fit(train_data_X, train_data_Y)\n",
    "\n",
    "print (\"Model-10 Accuracy: \",model_10.score(validation_data_X,validation_data_Y))\n",
    "print (\"Model-50 Accuracy: \",model_50.score(validation_data_X,validation_data_Y))\n",
    "print (\"Model-100 Accuracy: \",model_100.score(validation_data_X,validation_data_Y))\n",
    "print (\"Model-200 Accuracy: \",model_200.score(validation_data_X,validation_data_Y))\n",
    "print (\"Model-500 Accuracy: \",model_500.score(validation_data_X,validation_data_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_figure(dim, title, xlabel, ylabel, legend):\n",
    "    plt.rcParams['figure.figsize'] = dim\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if legend is not None:\n",
    "        plt.legend(loc=legend, prop={'size':15})\n",
    "    plt.rcParams.update({'font.size': 16})\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#error= 1-accuracy\n",
    "train_err_10 = 1-model_10.score(train_data_X,train_data_Y)\n",
    "train_err_50 = 1-model_50.score(train_data_X,train_data_Y)\n",
    "train_err_100 = 1-model_100.score(train_data_X,train_data_Y)\n",
    "train_err_200 = 1-model_200.score(train_data_X,train_data_Y)\n",
    "train_err_500 = 1-model_500.score(train_data_X,train_data_Y)\n",
    "\n",
    "training_errors = [train_err_10, train_err_50, train_err_100, \n",
    "                   train_err_200, train_err_500]\n",
    "\n",
    "validation_err_10 = 1-model_10.score(validation_data_X,validation_data_Y)\n",
    "validation_err_50 = 1-model_50.score(validation_data_X,validation_data_Y)\n",
    "validation_err_100 = 1-model_100.score(validation_data_X,validation_data_Y)\n",
    "validation_err_200 = 1-model_200.score(validation_data_X,validation_data_Y)\n",
    "validation_err_500 = 1-model_500.score(validation_data_X,validation_data_Y)\n",
    "\n",
    "validation_errors = [validation_err_10, validation_err_50, validation_err_100, \n",
    "                     validation_err_200, validation_err_500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([10, 50, 100, 200, 500], training_errors, linewidth=4.0, label='Training error')\n",
    "plt.plot([10, 50, 100, 200, 500], validation_errors, linewidth=4.0, label='Validation error')\n",
    "\n",
    "make_figure(dim=(10,5), title='Error vs number of trees',\n",
    "            xlabel='Number of trees',\n",
    "            ylabel='Classification error',\n",
    "            legend='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['grade',              # grade of the loan\n",
    "            'term',               # the term of the loan\n",
    "            'home_ownership',     # home ownership status: own, mortgage or rent\n",
    "            'emp_length',         # number of years of employment\n",
    "           ]\n",
    "loans['safe_loans'] = loans['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n",
    "loans.drop('bad_loans', axis = 'columns')\n",
    "target = 'safe_loans'\n",
    "loans = loans[features + [target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>grade</th>\n",
       "      <th>term</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>safe_loans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>60 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>&lt; 1 year</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>36 months</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3 years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122602</th>\n",
       "      <td>E</td>\n",
       "      <td>60 months</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122603</th>\n",
       "      <td>D</td>\n",
       "      <td>36 months</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122604</th>\n",
       "      <td>D</td>\n",
       "      <td>60 months</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>5 years</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122605</th>\n",
       "      <td>D</td>\n",
       "      <td>60 months</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>10+ years</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122606</th>\n",
       "      <td>A</td>\n",
       "      <td>36 months</td>\n",
       "      <td>OWN</td>\n",
       "      <td>3 years</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>122607 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       grade        term home_ownership emp_length  safe_loans\n",
       "0          B   36 months           RENT  10+ years           1\n",
       "1          C   60 months           RENT   < 1 year          -1\n",
       "2          C   36 months           RENT  10+ years           1\n",
       "3          C   36 months           RENT  10+ years           1\n",
       "4          A   36 months           RENT    3 years           1\n",
       "...      ...         ...            ...        ...         ...\n",
       "122602     E   60 months       MORTGAGE        NaN          -1\n",
       "122603     D   36 months       MORTGAGE  10+ years           1\n",
       "122604     D   60 months       MORTGAGE    5 years          -1\n",
       "122605     D   60 months       MORTGAGE  10+ years          -1\n",
       "122606     A   36 months            OWN    3 years           1\n",
       "\n",
       "[122607 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = loans.iloc[train_idx]\n",
    "test_data = loans.iloc[test_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 1443 observations from train data; keeping 35781 \n",
      "Dropping 349 observations from test data; keeping 8935 \n"
     ]
    }
   ],
   "source": [
    "##dropping rows with NaN values\n",
    "prev_train = len(train_data)\n",
    "train_data = train_data.dropna(axis=0, how='any')\n",
    "now_train = len(train_data)\n",
    "# Count the number of rows with missing data\n",
    "\n",
    "print ('Dropping %s observations from train data; keeping %s ' % (prev_train - now_train, now_train))\n",
    "\n",
    "prev_test = len(test_data)\n",
    "test_data = test_data.dropna(axis=0, how='any')\n",
    "now_test = len(test_data)\n",
    "# Count the number of rows with missing data\n",
    "\n",
    "print ('Dropping %s observations from test data; keeping %s ' % (prev_test - now_test, now_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "      <th>...</th>\n",
       "      <th>emp_length_10+ years</th>\n",
       "      <th>emp_length_2 years</th>\n",
       "      <th>emp_length_3 years</th>\n",
       "      <th>emp_length_4 years</th>\n",
       "      <th>emp_length_5 years</th>\n",
       "      <th>emp_length_6 years</th>\n",
       "      <th>emp_length_7 years</th>\n",
       "      <th>emp_length_8 years</th>\n",
       "      <th>emp_length_9 years</th>\n",
       "      <th>emp_length_&lt; 1 year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  grade_G  \\\n",
       "1           -1        0        0        1        0        0        0        0   \n",
       "6           -1        0        0        0        0        0        1        0   \n",
       "7           -1        0        1        0        0        0        0        0   \n",
       "10          -1        0        0        1        0        0        0        0   \n",
       "12          -1        0        1        0        0        0        0        0   \n",
       "\n",
       "    term_ 36 months  term_ 60 months  ...  emp_length_10+ years  \\\n",
       "1                 0                1  ...                     0   \n",
       "6                 0                1  ...                     0   \n",
       "7                 0                1  ...                     0   \n",
       "10                1                0  ...                     0   \n",
       "12                1                0  ...                     0   \n",
       "\n",
       "    emp_length_2 years  emp_length_3 years  emp_length_4 years  \\\n",
       "1                    0                   0                   0   \n",
       "6                    0                   0                   1   \n",
       "7                    0                   0                   0   \n",
       "10                   0                   0                   0   \n",
       "12                   0                   1                   0   \n",
       "\n",
       "    emp_length_5 years  emp_length_6 years  emp_length_7 years  \\\n",
       "1                    0                   0                   0   \n",
       "6                    0                   0                   0   \n",
       "7                    0                   0                   0   \n",
       "10                   0                   0                   0   \n",
       "12                   0                   0                   0   \n",
       "\n",
       "    emp_length_8 years  emp_length_9 years  emp_length_< 1 year  \n",
       "1                    0                   0                    1  \n",
       "6                    0                   0                    0  \n",
       "7                    0                   0                    1  \n",
       "10                   0                   0                    1  \n",
       "12                   0                   0                    0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_target = [col for col, datatype in zip(train_data.columns, train_data.dtypes) if datatype == object]\n",
    "train_data = pd.get_dummies(train_data, columns=dummy_target)\n",
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>safe_loans</th>\n",
       "      <th>grade_A</th>\n",
       "      <th>grade_B</th>\n",
       "      <th>grade_C</th>\n",
       "      <th>grade_D</th>\n",
       "      <th>grade_E</th>\n",
       "      <th>grade_F</th>\n",
       "      <th>grade_G</th>\n",
       "      <th>term_ 36 months</th>\n",
       "      <th>term_ 60 months</th>\n",
       "      <th>...</th>\n",
       "      <th>emp_length_10+ years</th>\n",
       "      <th>emp_length_2 years</th>\n",
       "      <th>emp_length_3 years</th>\n",
       "      <th>emp_length_4 years</th>\n",
       "      <th>emp_length_5 years</th>\n",
       "      <th>emp_length_6 years</th>\n",
       "      <th>emp_length_7 years</th>\n",
       "      <th>emp_length_8 years</th>\n",
       "      <th>emp_length_9 years</th>\n",
       "      <th>emp_length_&lt; 1 year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     safe_loans  grade_A  grade_B  grade_C  grade_D  grade_E  grade_F  \\\n",
       "24           -1        0        0        0        1        0        0   \n",
       "41           -1        1        0        0        0        0        0   \n",
       "60           -1        0        0        0        0        0        1   \n",
       "93           -1        0        0        0        1        0        0   \n",
       "132          -1        0        1        0        0        0        0   \n",
       "\n",
       "     grade_G  term_ 36 months  term_ 60 months  ...  emp_length_10+ years  \\\n",
       "24         0                0                1  ...                     0   \n",
       "41         0                1                0  ...                     1   \n",
       "60         0                0                1  ...                     0   \n",
       "93         0                0                1  ...                     1   \n",
       "132        0                1                0  ...                     0   \n",
       "\n",
       "     emp_length_2 years  emp_length_3 years  emp_length_4 years  \\\n",
       "24                    1                   0                   0   \n",
       "41                    0                   0                   0   \n",
       "60                    0                   0                   1   \n",
       "93                    0                   0                   0   \n",
       "132                   1                   0                   0   \n",
       "\n",
       "     emp_length_5 years  emp_length_6 years  emp_length_7 years  \\\n",
       "24                    0                   0                   0   \n",
       "41                    0                   0                   0   \n",
       "60                    0                   0                   0   \n",
       "93                    0                   0                   0   \n",
       "132                   0                   0                   0   \n",
       "\n",
       "     emp_length_8 years  emp_length_9 years  emp_length_< 1 year  \n",
       "24                    0                   0                    0  \n",
       "41                    0                   0                    0  \n",
       "60                    0                   0                    0  \n",
       "93                    0                   0                    0  \n",
       "132                   0                   0                    0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_target = [col for col, datatype in zip(test_data.columns, test_data.dtypes) if datatype == object]\n",
    "test_data = pd.get_dummies(test_data, columns=dummy_target)\n",
    "test_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_X = train_data.drop(['safe_loans'], axis='columns')\n",
    "test_data_X = test_data.drop(['safe_loans'], axis='columns')\n",
    "train_data_Y = train_data['safe_loans']\n",
    "test_data_Y = test_data['safe_loans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate_node_weighted_mistakes(labels_in_node, data_weights):\n",
    "    # Sum the weights of all entries with label +1\n",
    "    total_weight_positive = sum(data_weights[labels_in_node == +1])\n",
    "    \n",
    "    # Weight of mistakes for predicting all -1's is equal to the sum above\n",
    "    ### YOUR CODE HERE\n",
    "    weighted_mistakes_all_negative = total_weight_positive\n",
    "    \n",
    "    # Sum the weights of all entries with label -1\n",
    "    ### YOUR CODE HERE\n",
    "    total_weight_negative = sum(data_weights[labels_in_node == -1])\n",
    "    \n",
    "    # Weight of mistakes for predicting all +1's is equal to the sum above\n",
    "    ### YOUR CODE HERE\n",
    "    weighted_mistakes_all_positive = total_weight_negative\n",
    "    \n",
    "    # Return the tuple (weight, class_label) representing the lower of the two weights\n",
    "    #    class_label should be an integer of value +1 or -1.\n",
    "    # If the two weights are identical, return (weighted_mistakes_all_positive,+1)\n",
    "    ### YOUR CODE HERE\n",
    "    if  weighted_mistakes_all_negative >= weighted_mistakes_all_positive:\n",
    "        return (weighted_mistakes_all_positive,+1)\n",
    "    else:\n",
    "        return (weighted_mistakes_all_negative,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Checkpoint: Test your intermediate_node_weighted_mistakes function, run the following cell:\n",
    "example_labels = np.asarray([-1, -1, 1, 1, 1])\n",
    "example_data_weights = np.asarray([1., 2., .5, 1., 1.])\n",
    "if intermediate_node_weighted_mistakes(example_labels, example_data_weights) == (2.5, -1):\n",
    "    print ('Test passed!')\n",
    "else:\n",
    "    print ('Test failed... try again!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the data is identical in each feature, this function should return None\n",
    "\n",
    "def best_splitting_feature(data, features, target, data_weights):\n",
    "    \n",
    "    # These variables will keep track of the best feature and the corresponding error\n",
    "    best_feature = None\n",
    "    best_error = float('+inf') \n",
    "    num_points = float(len(data))\n",
    "    \n",
    "    # Loop through each feature to consider splitting on that feature\n",
    "    for feature in features:\n",
    "        \n",
    "        # The left split will have all data points where the feature value is 0\n",
    "        # The right split will have all data points where the feature value is 1\n",
    "        left_split = data[data[feature] == 0]\n",
    "        right_split = data[data[feature] == 1]\n",
    "        \n",
    "        # Apply the same filtering to data_weights to create left_data_weights, right_data_weights\n",
    "        ## YOUR CODE HERE\n",
    "        left_data_weights = data_weights[data[feature] == 0]\n",
    "        right_data_weights = data_weights[data[feature] == 1]\n",
    "                    \n",
    "        # DIFFERENT HERE\n",
    "        # Calculate the weight of mistakes for left and right sides\n",
    "        ## YOUR CODE HERE\n",
    "        left_weighted_mistakes, left_class = intermediate_node_weighted_mistakes(left_split[target], left_data_weights)\n",
    "        right_weighted_mistakes, right_class = intermediate_node_weighted_mistakes(right_split[target], right_data_weights)\n",
    "        \n",
    "        # DIFFERENT HERE\n",
    "        # Compute weighted error by computing\n",
    "        #  ( [weight of mistakes (left)] + [weight of mistakes (right)] ) / [total weight of all data points]\n",
    "        ## YOUR CODE HERE\n",
    "        error = (left_weighted_mistakes + right_weighted_mistakes)/float(sum(data_weights))\n",
    "        \n",
    "        # If this is the best error we have found so far, store the feature and the error\n",
    "        if error < best_error:\n",
    "            best_feature = feature\n",
    "            best_error = error\n",
    "    \n",
    "    # Return the best feature we found\n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "example_data_weights = np.asarray(len(train_data)* [1.5])\n",
    "fe = best_splitting_feature(train_data, my_new_feature, target, example_data_weights)\n",
    "assert fe == 'term_ 36 months', 'test failed!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_leaf(target_values, data_weights):\n",
    "    \n",
    "    # Create a leaf node\n",
    "    leaf = {'splitting_feature' : None,\n",
    "            'is_leaf': True}\n",
    "    \n",
    "    # Computed weight of mistakes.\n",
    "    # Store the predicted class (1 or -1) in leaf['prediction']\n",
    "    weighted_error, best_class = intermediate_node_weighted_mistakes(target_values, data_weights)\n",
    "    leaf['prediction'] = best_class\n",
    "    \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_decision_tree_create(data, features, target, data_weights, current_depth = 1, max_depth = 10):\n",
    "    remaining_features = features[:] # Make a copy of the features.\n",
    "    target_values = data[target]\n",
    "    print (\"--------------------------------------------------------------------\")\n",
    "    print (\"Subtree, depth = %s (%s data points).\" % (current_depth, len(target_values)))\n",
    "    \n",
    "    # Stopping condition 1. Error is 0.\n",
    "    if intermediate_node_weighted_mistakes(target_values, data_weights)[0] <= 1e-15:\n",
    "        print (\"Stopping condition 1 reached.\")                \n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # Stopping condition 2. No more features.\n",
    "    if remaining_features == []:\n",
    "        print (\"Stopping condition 2 reached.\")                \n",
    "        return create_leaf(target_values, data_weights)    \n",
    "    \n",
    "    # Additional stopping condition (limit tree depth)\n",
    "    if current_depth > max_depth:\n",
    "        print (\"Reached maximum depth. Stopping for now.\")\n",
    "        return create_leaf(target_values, data_weights)\n",
    "    \n",
    "    # If all the datapoints are the same, splitting_feature will be None. Create a leaf\n",
    "    splitting_feature = best_splitting_feature(data, features, target, data_weights)\n",
    "    remaining_features.remove(splitting_feature)\n",
    "        \n",
    "    left_split = data[data[splitting_feature] == 0]\n",
    "    right_split = data[data[splitting_feature] == 1]\n",
    "    \n",
    "    left_data_weights = data_weights[data[splitting_feature] == 0]\n",
    "    right_data_weights = data_weights[data[splitting_feature] == 1]\n",
    "    \n",
    "    print (\"Split on feature %s. (%s, %s)\" % (splitting_feature, len(left_split), len(right_split)))\n",
    "    \n",
    "    # Create a leaf node if the split is \"perfect\"\n",
    "    if len(left_split) == len(data):\n",
    "        print (\"Creating leaf node.\")\n",
    "        return create_leaf(left_split[target], data_weights)\n",
    "    if len(right_split) == len(data):\n",
    "        print (\"Creating leaf node.\")\n",
    "        return create_leaf(right_split[target], data_weights)\n",
    "    \n",
    "    # Repeat (recurse) on left and right subtrees\n",
    "    left_tree = weighted_decision_tree_create(\n",
    "        left_split, remaining_features, target, left_data_weights, current_depth + 1, max_depth)\n",
    "    right_tree = weighted_decision_tree_create(\n",
    "        right_split, remaining_features, target, right_data_weights, current_depth + 1, max_depth)\n",
    "    \n",
    "    return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': splitting_feature,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes(tree):\n",
    "    if tree['is_leaf']:\n",
    "        return 1\n",
    "    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making predictions with a weighted decision tree\n",
    "def classify(tree, x, annotate = False):   \n",
    "    # If the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        if annotate: \n",
    "            print (\"At leaf, predicting %s\" % tree['prediction'])\n",
    "        return tree['prediction'] \n",
    "    else:\n",
    "        # Split on feature.\n",
    "        split_feature_value = x[tree['splitting_feature']]\n",
    "        if annotate: \n",
    "            print (\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n",
    "        if split_feature_value == 0:\n",
    "            return classify(tree['left'], x, annotate)\n",
    "        else:\n",
    "            return classify(tree['right'], x, annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_error(tree, data):\n",
    "    # Apply the classify(tree, x) to each row in your data\n",
    "    prediction = data.apply(lambda x: classify(tree, x), axis = 1)\n",
    "    \n",
    "    # Once you've made the predictions, calculate the classification error\n",
    "    return (prediction != data[target]).sum() / float(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grade_A', 'grade_B', 'grade_C', 'grade_D', 'grade_E', 'grade_F', 'grade_G', 'term_ 36 months', 'term_ 60 months', 'home_ownership_MORTGAGE', 'home_ownership_OTHER', 'home_ownership_OWN', 'home_ownership_RENT', 'emp_length_1 year', 'emp_length_10+ years', 'emp_length_2 years', 'emp_length_3 years', 'emp_length_4 years', 'emp_length_5 years', 'emp_length_6 years', 'emp_length_7 years', 'emp_length_8 years', 'emp_length_9 years', 'emp_length_< 1 year']\n"
     ]
    }
   ],
   "source": [
    "my_new_feature = list(train_data.columns)\n",
    "my_new_feature.remove(target)\n",
    "print(my_new_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature term_ 36 months. (8997, 26784)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8997 data points).\n",
      "Split on feature grade_A. (8901, 96)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (8901 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (96 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26784 data points).\n",
      "Split on feature grade_D. (22290, 4494)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (22290 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (4494 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "# test code \n",
    "example_data_weights = np.asarray([1.0 for i in range(len(train_data))])\n",
    "small_data_decision_tree = weighted_decision_tree_create(train_data, my_new_feature, target, example_data_weights, max_depth=2)\n",
    "assert count_nodes(small_data_decision_tree) == 7, 'test failed!'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature home_ownership_RENT. (19645, 16136)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (19645 data points).\n",
      "Split on feature grade_F. (18768, 877)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (18768 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (877 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (16136 data points).\n",
      "Split on feature grade_D. (12857, 3279)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (12857 data points).\n",
      "Stopping condition 1 reached.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 3 (3279 data points).\n",
      "Stopping condition 1 reached.\n"
     ]
    }
   ],
   "source": [
    "# Assign weights\n",
    "example_data_weights = np.array([1.] * 10 + [0.]*(len(train_data) - 20) + [1.] * 10)\n",
    "# Train a weighted decision tree model.\n",
    "small_data_decision_tree_subset_20 = weighted_decision_tree_create(train_data, my_new_feature, target,\n",
    "                         example_data_weights, max_depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_leaf': False,\n",
       " 'prediction': None,\n",
       " 'splitting_feature': 'home_ownership_RENT',\n",
       " 'left': {'is_leaf': False,\n",
       "  'prediction': None,\n",
       "  'splitting_feature': 'grade_F',\n",
       "  'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1},\n",
       "  'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1}},\n",
       " 'right': {'is_leaf': False,\n",
       "  'prediction': None,\n",
       "  'splitting_feature': 'grade_D',\n",
       "  'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1},\n",
       "  'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data_decision_tree_subset_20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['safe_loans', 'grade_A', 'grade_B', 'grade_C', 'grade_D', 'grade_E',\n",
       "       'grade_F', 'grade_G', 'term_ 36 months', 'term_ 60 months',\n",
       "       'home_ownership_MORTGAGE', 'home_ownership_OTHER', 'home_ownership_OWN',\n",
       "       'home_ownership_RENT', 'emp_length_1 year', 'emp_length_10+ years',\n",
       "       'emp_length_2 years', 'emp_length_3 years', 'emp_length_4 years',\n",
       "       'emp_length_5 years', 'emp_length_6 years', 'emp_length_7 years',\n",
       "       'emp_length_8 years', 'emp_length_9 years', 'emp_length_< 1 year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4800033537352226"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(small_data_decision_tree_subset_20, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3948517067711248"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_classification_error(small_data_decision_tree, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "from math import exp\n",
    "\n",
    "def adaboost_with_tree_stumps(data, features, target, num_tree_stumps):\n",
    "    # start with unweighted data\n",
    "    alpha = np.array(([1.]*len(data)))\n",
    "    weights = []\n",
    "    tree_stumps = []\n",
    "    target_values = data[target]\n",
    "    \n",
    "    for t in range(num_tree_stumps):\n",
    "        print ('=====================================================')\n",
    "        print ('Adaboost Iteration %d' % t)\n",
    "        print ('=====================================================')        \n",
    "        # Learn a weighted decision tree stump. Use max_depth=1\n",
    "        tree_stump = weighted_decision_tree_create(data, features, target, data_weights=alpha, max_depth=1)\n",
    "        tree_stumps.append(tree_stump)\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions = data.apply(lambda x: classify(tree_stump, x), axis = 1)\n",
    "        \n",
    "        # Produce a Boolean array indicating whether\n",
    "        # each data point was correctly classified\n",
    "        is_correct = predictions == target_values\n",
    "        is_wrong   = predictions != target_values\n",
    "        \n",
    "        # Compute weighted error\n",
    "        # YOUR CODE HERE\n",
    "        weighted_error = np.sum(np.multiply(np.array(is_wrong), alpha)) * (1. / np.sum(alpha))\n",
    "        \n",
    "        # Compute model coefficient using weighted error\n",
    "        # YOUR CODE HERE\n",
    "        weight =  (1. / 2) * log((1 - weighted_error) * (1. / (weighted_error)))\n",
    "        weights.append(weight)\n",
    "        \n",
    "        # Adjust weights on data point\n",
    "        adjustment = is_correct.apply(lambda is_correct : exp(-weight) if is_correct else exp(weight))\n",
    "        \n",
    "        # Scale alpha by multiplying by adjustment\n",
    "        # Then normalize data points weights\n",
    "        ## YOUR CODE HERE \n",
    "        alpha = alpha * np.array(adjustment)\n",
    "        alpha = alpha / np.sum(alpha)\n",
    "    \n",
    "    return weights, tree_stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature term_ 36 months. (8997, 26784)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8997 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26784 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_A. (30886, 4895)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30886 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4895 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Checking your Adaboost code\n",
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, my_new_feature, target, num_tree_stumps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_adaboost(stump_weights, tree_stumps, data):\n",
    "    scores = np.array([0.]*len(data))\n",
    "    \n",
    "    for i, tree_stump in enumerate(tree_stumps):\n",
    "        predictions = data.apply(lambda x: classify(tree_stump, x), axis = 1)\n",
    "        \n",
    "        # Accumulate predictions on scores array\n",
    "        # YOUR CODE HERE\n",
    "        scores = scores + stump_weights[i] * np.array(predictions)\n",
    "    scores = pd.Series(scores)\n",
    "    return scores.apply(lambda score : +1 if score > 0 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data Accuracy of 10-component ensemble = 0.5632039350493279\n"
     ]
    }
   ],
   "source": [
    "train_data_predictions = predict_adaboost(stump_weights, tree_stumps, train_data)\n",
    "train_accuracy = np.sum(np.array(train_data[target]) == train_data_predictions) / float(len(train_data_predictions))\n",
    "print ('training data Accuracy of 10-component ensemble = %s' % train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'is_leaf': False,\n",
       "  'prediction': None,\n",
       "  'splitting_feature': 'term_ 36 months',\n",
       "  'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1},\n",
       "  'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}},\n",
       " {'is_leaf': False,\n",
       "  'prediction': None,\n",
       "  'splitting_feature': 'grade_A',\n",
       "  'left': {'splitting_feature': None, 'is_leaf': True, 'prediction': -1},\n",
       "  'right': {'splitting_feature': None, 'is_leaf': True, 'prediction': 1}}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 0\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature term_ 36 months. (8997, 26784)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8997 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26784 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 1\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_A. (30886, 4895)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30886 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4895 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 2\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_D. (29281, 6500)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (29281 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6500 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 3\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature home_ownership_MORTGAGE. (19017, 16764)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (19017 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (16764 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 4\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_B. (25833, 9948)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (25833 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9948 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 5\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_E. (32475, 3306)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32475 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3306 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 6\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_A. (30886, 4895)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30886 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4895 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 7\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_F. (34122, 1659)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34122 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1659 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 8\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_A. (30886, 4895)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30886 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4895 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 9\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_F. (34122, 1659)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34122 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1659 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 10\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_D. (29281, 6500)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (29281 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6500 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 11\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_B. (25833, 9948)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (25833 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9948 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 12\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_F. (34122, 1659)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34122 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1659 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 13\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature term_ 36 months. (8997, 26784)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8997 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26784 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 14\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split on feature grade_E. (32475, 3306)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32475 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3306 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 15\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_A. (30886, 4895)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (30886 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (4895 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 16\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_F. (34122, 1659)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34122 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1659 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 17\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length_4 years. (33150, 2631)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (33150 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2631 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 18\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_G. (35352, 429)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35352 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (429 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 19\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature emp_length_2 years. (32209, 3572)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32209 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3572 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 20\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_G. (35352, 429)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35352 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (429 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 21\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature home_ownership_OWN. (32959, 2822)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32959 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (2822 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 22\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_F. (34122, 1659)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (34122 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (1659 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 23\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature term_ 36 months. (8997, 26784)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (8997 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26784 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 24\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_E. (32475, 3306)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (32475 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (3306 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 25\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_C. (26737, 9044)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (26737 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9044 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 26\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_B. (25833, 9948)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (25833 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (9948 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 27\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_G. (35352, 429)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35352 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (429 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "=====================================================\n",
      "Adaboost Iteration 28\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_D. (29281, 6500)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (29281 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (6500 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "Adaboost Iteration 29\n",
      "=====================================================\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 1 (35781 data points).\n",
      "Split on feature grade_G. (35352, 429)\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (35352 data points).\n",
      "Reached maximum depth. Stopping for now.\n",
      "--------------------------------------------------------------------\n",
      "Subtree, depth = 2 (429 data points).\n",
      "Reached maximum depth. Stopping for now.\n"
     ]
    }
   ],
   "source": [
    "stump_weights, tree_stumps = adaboost_with_tree_stumps(train_data, \n",
    "                                 my_new_feature, target, num_tree_stumps=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, training error = 0.417148766104916\n",
      "Iteration 2, training error = 0.43679606495067214\n",
      "Iteration 3, training error = 0.39674687683407395\n",
      "Iteration 4, training error = 0.39674687683407395\n",
      "Iteration 5, training error = 0.38327604035661383\n",
      "Iteration 6, training error = 0.3903188843240826\n",
      "Iteration 7, training error = 0.38129174701657303\n",
      "Iteration 8, training error = 0.38788742628769457\n",
      "Iteration 9, training error = 0.38129174701657303\n",
      "Iteration 10, training error = 0.3831083535954836\n",
      "Iteration 11, training error = 0.3799502529275314\n",
      "Iteration 12, training error = 0.3799502529275314\n",
      "Iteration 13, training error = 0.3799502529275314\n",
      "Iteration 14, training error = 0.3799502529275314\n",
      "Iteration 15, training error = 0.3799502529275314\n",
      "Iteration 16, training error = 0.3799502529275314\n",
      "Iteration 17, training error = 0.3799502529275314\n",
      "Iteration 18, training error = 0.37992230513400965\n",
      "Iteration 19, training error = 0.37992230513400965\n",
      "Iteration 20, training error = 0.3801458874821833\n",
      "Iteration 21, training error = 0.3801458874821833\n",
      "Iteration 22, training error = 0.3801458874821833\n",
      "Iteration 23, training error = 0.37992230513400965\n",
      "Iteration 24, training error = 0.3801458874821833\n",
      "Iteration 25, training error = 0.3812637992230513\n",
      "Iteration 26, training error = 0.37992230513400965\n",
      "Iteration 27, training error = 0.3812637992230513\n",
      "Iteration 28, training error = 0.3812637992230513\n",
      "Iteration 29, training error = 0.38143148598418153\n",
      "Iteration 30, training error = 0.380453313210922\n"
     ]
    }
   ],
   "source": [
    "error_all = []\n",
    "for n in range(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], train_data)\n",
    "    error = np.sum(np.array(train_data[target]) != predictions) / float(len(predictions))\n",
    "    error_all.append(error)\n",
    "    print (\"Iteration %s, training error = %s\" % (n, error_all[n-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = 7, 5\n",
    "plt.plot(range(1,31), error_all, '-', linewidth=4.0, label='Training error')\n",
    "plt.title('Performance of Adaboost ensemble')\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('Classification error')\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, test error = 0.41891438164521544\n",
      "Iteration 2, test error = 0.43133743704532734\n",
      "Iteration 3, test error = 0.3948517067711248\n",
      "Iteration 4, test error = 0.3948517067711248\n",
      "Iteration 5, test error = 0.3791829882484611\n",
      "Iteration 6, test error = 0.3899272523782876\n",
      "Iteration 7, test error = 0.378735310576385\n",
      "Iteration 8, test error = 0.3878007834359261\n",
      "Iteration 9, test error = 0.378735310576385\n",
      "Iteration 10, test error = 0.3791829882484611\n",
      "Iteration 11, test error = 0.3773922775601567\n",
      "Iteration 12, test error = 0.3773922775601567\n",
      "Iteration 13, test error = 0.3773922775601567\n",
      "Iteration 14, test error = 0.3773922775601567\n",
      "Iteration 15, test error = 0.3773922775601567\n",
      "Iteration 16, test error = 0.3773922775601567\n",
      "Iteration 17, test error = 0.3773922775601567\n",
      "Iteration 18, test error = 0.37761611639619475\n",
      "Iteration 19, test error = 0.37761611639619475\n",
      "Iteration 20, test error = 0.3772803581421377\n",
      "Iteration 21, test error = 0.3772803581421377\n",
      "Iteration 22, test error = 0.3772803581421377\n",
      "Iteration 23, test error = 0.37761611639619475\n",
      "Iteration 24, test error = 0.3772803581421377\n",
      "Iteration 25, test error = 0.3772803581421377\n",
      "Iteration 26, test error = 0.37761611639619475\n",
      "Iteration 27, test error = 0.3772803581421377\n",
      "Iteration 28, test error = 0.3772803581421377\n",
      "Iteration 29, test error = 0.3773922775601567\n",
      "Iteration 30, test error = 0.37660884163402353\n"
     ]
    }
   ],
   "source": [
    "test_error_all = []\n",
    "for n in range(1, 31):\n",
    "    predictions = predict_adaboost(stump_weights[:n], tree_stumps[:n], test_data)\n",
    "    error = np.sum(np.array(test_data[target]) != predictions) / float(len(predictions))\n",
    "    test_error_all.append(error)\n",
    "    print (\"Iteration %s, test error = %s\" % (n, test_error_all[n-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.figsize'] = 7, 5\n",
    "plt.plot(range(1,31), error_all, '-', linewidth=4.0, label='Training error')\n",
    "plt.plot(range(1,31), test_error_all, '-', linewidth=4.0, label='Test error')\n",
    "\n",
    "plt.title('Performance of Adaboost ensemble')\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('Classification error')\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "plt.legend(loc='best', prop={'size':15})\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
