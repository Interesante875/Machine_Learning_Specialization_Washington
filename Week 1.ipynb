{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import turicreate as tc\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict = {'name':str, 'review':str, 'rating':float}\n",
    "products = tc.SFrame('m_bfaa91c17752f745.frame_idx')\n",
    "products_pd = pd.read_csv('amazon_baby.csv', dtype=dtype_dict)\n",
    "products = products.fillna('review','')\n",
    "products_pd = products_pd.fillna({'review':''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 183531 entries, 0 to 183530\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   name    183213 non-null  object \n",
      " 1   review  183531 non-null  object \n",
      " 2   rating  183531 non-null  float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 4.2+ MB\n"
     ]
    }
   ],
   "source": [
    "products_pd.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('','',string.punctuation)\n",
    "    return text.translate(translator) \n",
    "#products['review_clean'] = products['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Using default 16 lambda workers.</pre>"
      ],
      "text/plain": [
       "Using default 16 lambda workers."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>To maximize the degree of parallelism, add the following code to the beginning of the program:</pre>"
      ],
      "text/plain": [
       "To maximize the degree of parallelism, add the following code to the beginning of the program:"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>\"turicreate.config.set_runtime_config('TURI_DEFAULT_NUM_PYLAMBDA_WORKERS', 32)\"</pre>"
      ],
      "text/plain": [
       "\"turicreate.config.set_runtime_config('TURI_DEFAULT_NUM_PYLAMBDA_WORKERS', 32)\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Note that increasing the degree of parallelism also increases the memory footprint.</pre>"
      ],
      "text/plain": [
       "Note that increasing the degree of parallelism also increases the memory footprint."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "products['review_clean'] = products['review'].apply(remove_punctuation)\n",
    "products_pd['review_clean'] = products_pd['review'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(products['review_clean'][2])\n",
    "print(products['review'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = products[products['rating'] != 3]\n",
    "products_pd = products_pd[products_pd['rating'] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "products['sentiment'] = products['rating'].apply(lambda rating : +1 if rating > 3 else -1)\n",
    "products_pd['sentiment'] = products_pd['rating'].apply(lambda rating : +1 if rating > 3 else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('module-2-assignment-test-idx.json') as test_data_file:    \n",
    "    test_data_idx = json.load(test_data_file)\n",
    "with open('module-2-assignment-train-idx.json') as train_data_file:    \n",
    "    train_data_idx = json.load(train_data_file)\n",
    "\n",
    "train_data = products_pd.iloc[train_data_idx]\n",
    "test_data = products_pd.iloc[test_data_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train_data, test_data = products.random_split(.8, seed=1)\n",
    "train_data_pd, test_data_pd, y_train_pd, y_test_pd = train_test_split(\n",
    "    products_pd[['name', 'review', 'rating','review_clean']], \n",
    "    products_pd['sentiment'], \n",
    "    test_size=0.2, random_state=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "vectorizer = CountVectorizer(token_pattern=r'\\b\\w+\\b')\n",
    "     # Use this token pattern to keep single-letter words\n",
    "# First, learn vocabulary from the training data and assign columns to words\n",
    "# Then convert the training data into a sparse matrix\n",
    "train_matrix = vectorizer.fit_transform(train_data['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix = vectorizer.transform(test_data['review_clean'])\n",
    "train_matrix_pd = vectorizer.fit_transform(train_data_pd['review_clean'])\n",
    "# Second, convert the test data into a sparse matrix, using the same word-column mapping\n",
    "test_matrix_pd = vectorizer.transform(test_data_pd['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_model = linear_model.LogisticRegression()\n",
    "sentiment_model.fit(train_matrix, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90357"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(sentiment_model.coef_ >= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(sentiment_model.intercept_ >= 0) + np.count_nonzero(sentiment_model.coef_ >= 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  1]\n",
      "[[7.52087610e-03 9.92479124e-01]\n",
      " [9.57188195e-01 4.28118053e-02]\n",
      " [9.99958420e-01 4.15795848e-05]]\n"
     ]
    }
   ],
   "source": [
    "sample_test_data = test_data.iloc[10:13]\n",
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "print(sentiment_model.classes_)\n",
    "print(sentiment_model.predict_proba(sample_test_matrix))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data[0]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data[1]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_test_data[2]['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.88252334  -3.10718613 -10.08785968]\n"
     ]
    }
   ],
   "source": [
    "sample_test_matrix = vectorizer.transform(sample_test_data['review_clean'])\n",
    "scores = sentiment_model.decision_function(sample_test_matrix)\n",
    "print (scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "predicted_test_sample = sentiment_model.predict(sample_test_matrix)\n",
    "print(predicted_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7.52087610e-03 9.92479124e-01]\n",
      " [9.57188195e-01 4.28118053e-02]\n",
      " [9.99958420e-01 4.15795848e-05]]\n"
     ]
    }
   ],
   "source": [
    "probability_test_sample = sentiment_model.predict_proba(sample_test_matrix)\n",
    "print(probability_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "lowest = np.argmin(probability_test_sample, axis = 0)\n",
    "print(lowest[1] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_test_data = sentiment_model.predict_proba(test_matrix)\n",
    "predicted_test_sample = sentiment_model.predict(test_matrix)\n",
    "test_data['positive probability'] = [x[1] for x in np.asarray(probability_test_data)]\n",
    "top_positive_reviews = test_data.sort_values(by='positive probability',ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87017       Baby Einstein Around The World Discovery Center\n",
       "147996    Baby Jogger City Mini GT Double Stroller, Shad...\n",
       "147949    Baby Jogger City Mini GT Single Stroller, Shad...\n",
       "133651                    Britax 2012 B-Agile Stroller, Red\n",
       "166827    Britax Boulevard 70-G3 Convertible Car Seat Se...\n",
       "168081    Buttons Cloth Diaper Cover - One Size - 8 Colo...\n",
       "140816           Diono RadianRXT Convertible Car Seat, Plum\n",
       "66059          Evenflo 6 Pack Classic Glass Bottle, 4-Ounce\n",
       "52631     Evenflo X Sport Plus Convenience Stroller - Ch...\n",
       "114796    Fisher-Price Cradle 'N Swing,  My Little Snuga...\n",
       "168697    Graco FastAction Fold Jogger Click Connect Str...\n",
       "137034           Graco Pack 'n Play Element Playard - Flint\n",
       "165593    Ikea 36 Pcs Kalas Kids Plastic BPA Free Flatwa...\n",
       "100166    Infantino Wrap and Tie Baby Carrier, Black Blu...\n",
       "180646        Mamas &amp; Papas 2014 Urbo2 Stroller - Black\n",
       "50315            P'Kolino Silly Soft Seating in Tias, Green\n",
       "119182    Roan Rocco Classic Pram Stroller 2-in-1 with B...\n",
       "80155     Simple Wishes Hands-Free Breastpump Bra, Pink,...\n",
       "14008         Stork Craft Beatrice Combo Tower Chest, White\n",
       "182089    Summer Infant Wide View Digital Color Video Mo...\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_positive_reviews['name'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['negative probability'] = [x[0] for x in np.asarray(probability_test_data)]\n",
    "top_negative_reviews = test_data.sort_values(by='negative probability',ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94560     The First Years True Choice P400 Premium Digit...\n",
       "16042           Fisher-Price Ocean Wonders Aquarium Bouncer\n",
       "120209    Levana Safe N'See Digital Video Baby Monitor w...\n",
       "155287    VTech Communications Safe &amp; Sounds Full Co...\n",
       "48694     Adiri BPA Free Natural Nurser Ultimate Bottle ...\n",
       "95420          One Step Ahead Hide-Away Extra Long Bed Rail\n",
       "53207                   Safety 1st High-Def Digital Monitor\n",
       "176046         Baby Trend Inertia Infant Car Seat - Horizon\n",
       "167249    Samsung SEW-3037W Wireless Pan Tilt Video Baby...\n",
       "81332                 Cloth Diaper Sprayer--styles may vary\n",
       "94389                  Snuza Portable Baby Movement Monitor\n",
       "59546                Ellaroo Mei Tai Baby Carrier - Hershey\n",
       "31741                Regalo My Cot Portable Bed, Royal Blue\n",
       "76000            Peg-Perego Tatamia High Chair, White Latte\n",
       "77072        Safety 1st Exchangeable Tip 3 in 1 Thermometer\n",
       "96572      Baby Jogger Summit XC Double Stroller, Red/Black\n",
       "1116                  Safety 1st Deluxe 4-in-1 Bath Station\n",
       "113995    Motorola Digital Video Baby Monitor with Room ...\n",
       "10677                     Philips AVENT Newborn Starter Set\n",
       "75994            Peg-Perego Tatamia High Chair, White Latte\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_negative_reviews['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.93\n"
     ]
    }
   ],
   "source": [
    "def get_classification_accuracy(model, data, true_labels):\n",
    "    pred_y = model.predict(data)\n",
    "    correct = np.sum(pred_y==true_labels)\n",
    "    accuracy = round(correct/len(true_labels), 2)\n",
    "    return accuracy\n",
    "\n",
    "accuracy_prob = get_classification_accuracy(sentiment_model, test_matrix, test_data[\"sentiment\"])\n",
    "print(accuracy_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_words = ['love', 'great', 'easy', 'old', 'little', 'perfect', 'loves', \n",
    "      'well', 'able', 'car', 'broke', 'less', 'even', 'waste', 'disappointed', \n",
    "      'work', 'product', 'money', 'would', 'return']\n",
    "\n",
    "vectorizer_word_subset = CountVectorizer(vocabulary=significant_words) # limit to 20 words\n",
    "train_matrix_word_subset = vectorizer_word_subset.fit_transform(train_data['review_clean'])\n",
    "test_matrix_word_subset = vectorizer_word_subset.transform(test_data['review_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, ..., 0, 1, 0],\n",
       "       [2, 0, 1, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 1, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_matrix_word_subset.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model = linear_model.LogisticRegression()\n",
    "simple_model.fit(train_matrix_word_subset, train_data['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model_coef_table = sframe.SFrame({'word':significant_words,\n",
    "                                         'coefficient':simple_model.coef_.flatten()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model_coefficient = pd.DataFrame(\n",
    "    {'word':significant_words,'simple_model_coefficient':simple_model.coef_.flatten()}).sort_values(\n",
    "    ['simple_model_coefficient'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "len(simple_model_coefficient[simple_model_coefficient[\"simple_model_coefficient\"]>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "accuracy_simple = get_classification_accuracy(simple_model, train_matrix_word_subset, train_data['sentiment'])\n",
    "accuracy_complex = get_classification_accuracy(sentiment_model, train_matrix, train_data['sentiment'])\n",
    "print(accuracy_simple)\n",
    "print(accuracy_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment Model:  0.93\n",
      "Simple Model:  0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"Sentiment Model: \",get_classification_accuracy(sentiment_model,test_matrix,test_data[\"sentiment\"]))\n",
    "print(\"Simple Model: \",get_classification_accuracy(simple_model,test_matrix_word_subset,test_data[\"sentiment\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>5241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>28095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  sentiment  count\n",
       "0             -1   5241\n",
       "1              1  28095"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq=pd.crosstab(test_data[\"sentiment\"], columns=[\"count\"]).reset_index()\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model:  0.84\n"
     ]
    }
   ],
   "source": [
    "baseline_model=round(freq[freq[\"sentiment\"]==1][\"count\"].values[0]/freq[\"count\"].sum(),2)\n",
    "print(\"Baseline Model: \", baseline_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
